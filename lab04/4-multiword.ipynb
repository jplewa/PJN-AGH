{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4: Multiword expressions identification and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import locale\n",
    "import math\n",
    "import os\n",
    "import spacy\n",
    "import spacy.lang.pl\n",
    "import spacy.tokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl_PL.UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_COLLATE, 'pl_PL.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT_DIRECTORY = '../files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SpaCy tokenizer API to tokenize the text from the law corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizacja została wykonana przy pomocy kodu z poprzednich zajęć. Tokeny zostały przekonwertowane do samych małych liter oraz usunięte zostały białe znaki na początku i na końcu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pl_core_news_sm')\n",
    "# Create a Tokenizer with the default settings for Polish\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_file = {}\n",
    "\n",
    "for root, _, files in os.walk(ACT_DIRECTORY):\n",
    "    for file_name in files:\n",
    "        path = os.path.join(root, file_name)\n",
    "        with open(path, encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            tokens = [\n",
    "                token.text.lower().strip() \n",
    "                for token \n",
    "                in tokenizer(content)\n",
    "            ]\n",
    "            tokens_per_file[path] = [token for token in tokens if token != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute bigram counts of downcased tokens. \n",
    "Given the sentence: \"The quick brown fox jumps over the lazy dog.\", the bigram counts are as follows:\n",
    "* \"the quick\": 1\n",
    "* \"quick brown\": 1\n",
    "* \"brown fox\": 1\n",
    "* ...\n",
    "* \"dog .\": 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowana została generyczna metoda do zliczania n-gramów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams(tokens, n=2):\n",
    "    ngram_dict = collections.defaultdict(int)\n",
    "    for words in zip(*[tokens[offset:] for offset in (range(n))]):\n",
    "        ngram_dict[' '.join(words)] += 1\n",
    "    return ngram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = collections.defaultdict(int)\n",
    "\n",
    "for file, tokens in tokens_per_file.items():\n",
    "    for bigram, count in count_ngrams(tokens).items():\n",
    "        bigram_counts[bigram] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('art .', 84214),\n",
       " ('ust .', 53600),\n",
       " ('poz .', 45455),\n",
       " (', poz', 43395),\n",
       " ('. 1', 40043),\n",
       " ('- -', 36548),\n",
       " ('r .', 33165),\n",
       " ('w art', 32188),\n",
       " (', o', 30040),\n",
       " ('mowa w', 28577),\n",
       " ('. 2', 26811),\n",
       " ('w ust', 23584),\n",
       " ('. art', 23029),\n",
       " (', w', 22569),\n",
       " ('. nr', 21491),\n",
       " ('2 .', 21372),\n",
       " ('1 .', 21347),\n",
       " (', z', 19769),\n",
       " (') w', 18361),\n",
       " ('. 3', 17197)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigram_counts.items(), key=lambda bigram_count: -bigram_count[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do wykrycia znaków innych niż litery wykorzystana została metoda `isalpha()` klasy str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = {\n",
    "    bigram: count \n",
    "    for (bigram, count) \n",
    "    in bigram_counts.items()\n",
    "    if all([token.isalpha() for token in bigram.split(' ')])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w art', 32188),\n",
       " ('mowa w', 28577),\n",
       " ('w ust', 23584),\n",
       " ('o których', 13942),\n",
       " ('których mowa', 13915),\n",
       " ('otrzymuje brzmienie', 9604),\n",
       " ('z dnia', 9579),\n",
       " ('o którym', 9224),\n",
       " ('którym mowa', 9211),\n",
       " ('do spraw', 8731),\n",
       " ('i nr', 8464),\n",
       " ('dodaje się', 8235),\n",
       " ('w brzmieniu', 7329),\n",
       " ('w drodze', 7137),\n",
       " ('na podstawie', 6720),\n",
       " ('stosuje się', 6565),\n",
       " ('w przypadku', 6069),\n",
       " ('o której', 5537),\n",
       " ('której mowa', 5518),\n",
       " ('w zakresie', 5487)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigram_counts.items(), key=lambda bigram_count: -bigram_count[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pointwise mutual information to compute the measure for all pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw policzone zostało występowanie unigramów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = collections.defaultdict(int)\n",
    "\n",
    "for file, tokens in tokens_per_file.items():\n",
    "    for unigram, count in count_ngrams(tokens, n=1).items():\n",
    "        unigram_counts[unigram] += count\n",
    "        \n",
    "unigram_counts = {\n",
    "    unigram: count \n",
    "    for (unigram, count) \n",
    "    in unigram_counts.items()\n",
    "    if unigram.isalpha()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w', 202063),\n",
       " ('i', 90324),\n",
       " ('art', 84246),\n",
       " ('z', 82814),\n",
       " ('o', 65202),\n",
       " ('do', 60977),\n",
       " ('ust', 53686),\n",
       " ('na', 50805),\n",
       " ('lub', 46100),\n",
       " ('się', 46066),\n",
       " ('poz', 45481),\n",
       " ('nr', 45157),\n",
       " ('oraz', 33654),\n",
       " ('r', 33337),\n",
       " ('mowa', 28891),\n",
       " ('nie', 23069),\n",
       " ('przez', 21026),\n",
       " ('pkt', 19287),\n",
       " ('dnia', 18051),\n",
       " ('których', 17996)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unigram_counts.items(), key=lambda unigram_count: -unigram_count[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie te informacje wykorzystane zostały do policzenia PMI w oparciu o wzory z Wikipedii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_unigram_count = sum(unigram_counts.values())    \n",
    "total_bigram_count = sum(bigram_counts.values())    \n",
    "\n",
    "# log2(P(x, y) / (P(x) * P(y)))\n",
    "def pmi2(bigram, separator=' '):\n",
    "    first_token, second_token = bigram.split(separator)\n",
    "    first_token_p = unigram_counts[first_token] / total_unigram_count\n",
    "    second_token_p = unigram_counts[second_token] / total_unigram_count\n",
    "    bigram_p = bigram_counts[bigram] / total_bigram_count\n",
    "    return math.log2(bigram_p / (first_token_p * second_token_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_pmi = {\n",
    "    bigram: pmi2(bigram)\n",
    "    for (bigram, count)\n",
    "    in bigram_counts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ustawa z', 4.379094558700088),\n",
       " ('z dnia', 4.909796997264667),\n",
       " ('o zmianie', 5.943648353608395),\n",
       " ('zmianie ustawy', 7.632285568189541),\n",
       " ('ustawy o', 2.997759971025661),\n",
       " ('o utworzeniu', 5.972490051142801),\n",
       " ('utworzeniu agencji', 9.655040545312778),\n",
       " ('agencji techniki', 8.103824919750567),\n",
       " ('techniki i', 3.2836566055921494),\n",
       " ('i technologii', 3.7168414515812525)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram_pmi.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('znająca pjm', 22.161515861722478),\n",
       " ('przynęt zatrutych', 22.161515861722478),\n",
       " ('magazynkiem mieszczącym', 22.161515861722478),\n",
       " ('torowiskach zasp', 22.161515861722478),\n",
       " ('najmniejszy promień', 22.161515861722478),\n",
       " ('ręczny miotacz', 22.161515861722478),\n",
       " ('klifów nadmorskich', 22.161515861722478),\n",
       " ('głazów narzutowych', 22.161515861722478),\n",
       " ('fenolami lotnymi', 22.161515861722478),\n",
       " ('ostrzeżony strzałami', 22.161515861722478)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigram_pmi.items(), key=lambda bigram_pmi: -bigram_pmi[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset (>=5 occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bigram_pmi = {\n",
    "    bigram: pmi\n",
    "    for (bigram, pmi)\n",
    "    in bigram_pmi.items()\n",
    "    if bigram_counts[bigram] >= 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grzegorz schetyna', 19.839587766835116),\n",
       " ('obiegów chłodzących', 19.839587766835116),\n",
       " ('otworami wiertniczymi', 19.839587766835116),\n",
       " ('świeckie przygotowujące', 19.839587766835116),\n",
       " ('klęskami żywiołowymi', 19.839587766835116),\n",
       " ('środa wlkp', 19.839587766835116),\n",
       " ('obcowania płciowego', 19.839587766835116),\n",
       " ('nietykalność cielesną', 19.839587766835116),\n",
       " ('ręcznego miotacza', 19.839587766835116),\n",
       " ('młyny kulowe', 19.839587766835116)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(filtered_bigram_pmi.items(), key=lambda bigram_pmi: -bigram_pmi[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use log likelihood ratio (LLR) to compute the measure for all pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do wyliczenia LLR wykorzystana została [gotowa implementacja podlinkowana w zadaniu](https://github.com/tdunning/python-llr/blob/master/llr.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llr_2x2(k11, k12, k21, k22):\n",
    "    '''Special case of llr with a 2x2 table'''\n",
    "    return 2 * (denormEntropy([k11+k12, k21+k22]) +\n",
    "                denormEntropy([k11+k21, k12+k22]) -\n",
    "                denormEntropy([k11, k12, k21, k22]))\n",
    "\n",
    "def denormEntropy(counts):\n",
    "    '''Computes the entropy of a list of counts scaled by the sum of the counts. If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "    counts = list(counts)\n",
    "    total = float(sum(counts))\n",
    "    # Note tricky way to avoid 0*log(0)\n",
    "    return -sum([k * math.log(k/total + (k==0)) for k in counts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zliczone zostało wystąpienie poszczególnych tokenów jako kolejno pierwsze i drugie słowo w bigramie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_first_token_count = collections.defaultdict(int)\n",
    "bigram_second_token_count = collections.defaultdict(int)\n",
    "\n",
    "for bigram, count in bigram_counts.items():\n",
    "    first_token, second_token = bigram.split(' ')\n",
    "    bigram_first_token_count[first_token] += count\n",
    "    bigram_second_token_count[second_token] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_llr = {}\n",
    "\n",
    "for bigram, count in bigram_counts.items():\n",
    "    first_token, second_token = bigram.split(' ')\n",
    "    k11 = count\n",
    "    k12 = bigram_second_token_count[second_token] - count\n",
    "    k21 = bigram_first_token_count[first_token] - count\n",
    "    k22 = total_bigram_count - (k11 + k12 + k21)\n",
    "    \n",
    "    bigram_llr[bigram] = llr_2x2(k11, k12, k21, k22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ustawa z', 5232.874111163081),\n",
       " ('z dnia', 49825.50661258155),\n",
       " ('o zmianie', 8652.599377553095),\n",
       " ('zmianie ustawy', 7737.8292541178525),\n",
       " ('ustawy o', 5771.08663096017),\n",
       " ('o utworzeniu', 961.7506792048225),\n",
       " ('utworzeniu agencji', 366.47751015823815),\n",
       " ('agencji techniki', 80.42621761053306),\n",
       " ('techniki i', 82.29314483352937),\n",
       " ('i technologii', 118.54199846053962)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram_llr.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the word pairs according to that measure in the descending order and display top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mowa w', 178294.93722869083),\n",
       " ('otrzymuje brzmienie', 118778.94002869757),\n",
       " ('których mowa', 115960.97862050205),\n",
       " ('w art', 114780.25651876233),\n",
       " ('o których', 93619.1286106814),\n",
       " ('w ust', 88051.17502383213),\n",
       " ('którym mowa', 74918.5584188212),\n",
       " ('dodaje się', 66931.82314493437),\n",
       " ('do spraw', 61239.29428788787),\n",
       " ('o którym', 59613.87079361593)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigram_llr.items(), key=lambda bigram_llr: -bigram_llr[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trigram counts for the whole corpus and perform the same filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Występiwanie trigramów zostało zliczone przy pomocy przygotowanej wcześniej metody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = collections.defaultdict(int)\n",
    "\n",
    "for file, tokens in tokens_per_file.items():\n",
    "    for trigram, count in count_ngrams(tokens, n=3).items():\n",
    "        trigram_counts[trigram] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(', poz .', 43373),\n",
       " ('- - -', 34646),\n",
       " ('w art .', 32178),\n",
       " ('w ust .', 23547),\n",
       " ('ust . 1', 23356),\n",
       " ('. art .', 23024),\n",
       " ('r . nr', 17914),\n",
       " ('_ _ _', 16213),\n",
       " ('. 1 .', 15693),\n",
       " ('. 2 .', 15339),\n",
       " ('o których mowa', 13914),\n",
       " ('których mowa w', 13864),\n",
       " (', o których', 13832),\n",
       " (': 1 )', 13530),\n",
       " ('mowa w ust', 13493),\n",
       " ('mowa w art', 12372),\n",
       " (') w art', 11761),\n",
       " ('ust . 2', 10756),\n",
       " ('. 3 .', 9698),\n",
       " ('otrzymuje brzmienie :', 9556)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trigram_counts.items(), key=lambda trigram_count: -trigram_count[1])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = {\n",
    "    trigram: count \n",
    "    for (trigram, count) \n",
    "    in trigram_counts.items()\n",
    "    if all([token.isalpha() for token in trigram.split(' ')])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('o których mowa', 13914),\n",
       " ('których mowa w', 13864),\n",
       " ('mowa w ust', 13493),\n",
       " ('mowa w art', 12372),\n",
       " ('o którym mowa', 9209),\n",
       " ('którym mowa w', 9187),\n",
       " ('o której mowa', 5518),\n",
       " ('której mowa w', 5495),\n",
       " ('w drodze rozporządzenia', 4691),\n",
       " ('właściwy do spraw', 4635),\n",
       " ('minister właściwy do', 4615),\n",
       " ('ustawie z dnia', 3662),\n",
       " ('w ustawie z', 3658),\n",
       " ('stosuje się odpowiednio', 3103),\n",
       " ('ustawy z dnia', 3076),\n",
       " ('zastępuje się wyrazami', 2940),\n",
       " ('dodaje się ust', 2767),\n",
       " ('wejścia w życie', 2361),\n",
       " ('dni od dnia', 2076),\n",
       " ('się następujące zmiany', 1808)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trigram_counts.items(), key=lambda trigram_count: -trigram_count[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PMI (with 5 occurrence threshold) and LLR to compute top 10 results for the trigrams. Devise a method for computing the values, based on the results for bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMI zostało wyliczone przy pomocy wzoru analogicznego to przypadku bigramu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trigram_count = sum(trigram_counts.values())    \n",
    "\n",
    "# log2(P(x, y, z) / (P(x) * P(y) * P(z)))\n",
    "def pmi3(trigram, separator=' '):\n",
    "    first_token, second_token, third_token = trigram.split(separator)\n",
    "    first_token_p = unigram_counts[first_token] / total_unigram_count\n",
    "    second_token_p = unigram_counts[second_token] / total_unigram_count\n",
    "    third_token_p = unigram_counts[third_token] / total_unigram_count\n",
    "    trigram_p = trigram_counts[trigram] / total_trigram_count\n",
    "    return math.log2(trigram_p / (first_token_p * second_token_p * third_token_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ostrzeżony strzałami ostrzegawczymi', 44.23724557324892),\n",
       " ('przekazowi pieniężnemu towarzyszyły', 44.23724557324892),\n",
       " ('grzyba synchytrium endobioticum', 44.23724557324892),\n",
       " ('clavibacter michiganensis ssp', 44.23724557324892),\n",
       " ('krzewiące etos społecznikowski', 44.23724557324892),\n",
       " ('wniebowzięcia najświętszej maryi', 44.23724557324892),\n",
       " ('najświętszej maryi panny', 44.23724557324892),\n",
       " ('salus aegroti suprema', 44.23724557324892),\n",
       " ('aegroti suprema lex', 44.23724557324892),\n",
       " ('prawosławnym metropolitą warszawskim', 44.23724557324892)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_pmi = {\n",
    "    trigram: pmi3(trigram)\n",
    "    for (trigram, count)\n",
    "    in trigram_counts.items()\n",
    "}\n",
    "\n",
    "sorted(trigram_pmi.items(), key=lambda trigram_pmi: -trigram_pmi[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finałowego turnieju mistrzostw', 37.07737423647053),\n",
       " ('profilem zaufanym epuap', 36.83636613696674),\n",
       " ('cienką sierścią zwierzęcą', 36.777813954611624),\n",
       " ('przedwczesnego wyrębu drzewostanu', 36.652283072527766),\n",
       " ('turnieju mistrzostw europy', 36.31183949010756),\n",
       " ('potwierdzonym profilem zaufanym', 36.288878341664244),\n",
       " ('szybkiemu postępowi technicznemu', 36.16042997619809),\n",
       " ('piłce nożnej uefa', 36.14132115325039),\n",
       " ('centralnemu biuru antykorupcyjnemu', 36.12872111647076),\n",
       " ('wypalonym paliwem jądrowym', 35.938037554861644)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_trigram_pmi = {\n",
    "    trigram: pmi\n",
    "    for (trigram, pmi)\n",
    "    in trigram_pmi.items()\n",
    "    if trigram_counts[trigram] >= 5\n",
    "}\n",
    "\n",
    "sorted(filtered_trigram_pmi.items(), key=lambda trigram_pmi: -trigram_pmi[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy wyliczaniu LLR pary słów występujących w trigramie zostały potraktowane analogicznie do tokenów w przypadku bigramów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_first_pair_count = collections.defaultdict(int)\n",
    "trigram_second_pair_count = collections.defaultdict(int)\n",
    "\n",
    "for trigram, count in trigram_counts.items():\n",
    "    first_token, second_token, third_token = trigram.split(' ')\n",
    "    \n",
    "    first_pair = f'{first_token} {second_token}'\n",
    "    second_pair = f'{second_token} {third_token}'\n",
    "    \n",
    "    trigram_first_pair_count[first_pair] += count\n",
    "    trigram_second_pair_count[second_pair] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_llr = {}\n",
    "\n",
    "for trigram, count in trigram_counts.items():\n",
    "    first_token, second_token, third_token = trigram.split(' ')\n",
    "    \n",
    "    first_pair = f'{first_token} {second_token}'\n",
    "    second_pair = f'{second_token} {third_token}'\n",
    "    \n",
    "    k11 = count\n",
    "    k12 = trigram_second_pair_count[second_pair] - count\n",
    "    k21 = trigram_first_pair_count[first_pair] - count\n",
    "    k22 = total_trigram_count - (k11 + k12 + k21)\n",
    "    \n",
    "    trigram_llr[trigram] = llr_2x2(k11, k12, k21, k22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('o których mowa', 168955.57335261998),\n",
       " ('których mowa w', 128677.68434874358),\n",
       " ('o którym mowa', 119516.38820732615),\n",
       " ('mowa w ust', 112720.72532532585),\n",
       " ('mowa w art', 91866.20358409919),\n",
       " ('którym mowa w', 83294.26652510924),\n",
       " ('o której mowa', 77146.35895224831),\n",
       " ('minister właściwy do', 64516.70557209867),\n",
       " ('w drodze rozporządzenia', 58164.02565077676),\n",
       " ('właściwy do spraw', 52909.678427205945)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trigram_llr.items(), key=lambda trigram_llr: -trigram_llr[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table comparing the methods (separate table for bigrams and trigrams)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram\n",
    "\n",
    "| #| PMI | PMI (>=5 wystąpień) | LLR |\n",
    "|-|-|-|-|\n",
    "|1|_znająca pjm_ | _grzegorz schetyna_|_mowa w_|\n",
    "|2|_przynęt zatrutych_|_obiegów chłodzących_|_otrzymuje brzmienie_|\n",
    "|3|_magazynkiem mieszczącym_|_otworami wiertniczymi_|_których mowa_|\n",
    "|4|_torowiskach zasp_|_świeckie przygotowujące_|_w art_|\n",
    "|5|_najmniejszy promień_|_klęskami żywiołowymi_|_o których_|\n",
    "|6|_ręczny miotacz_|_środa wlkp_|_w ust_|\n",
    "|7|_klifów nadmorskich_|_obcowania płciowego_|_którym mowa_|\n",
    "|8|_głazów narzutowych_|_nietykalność cielesną_|_dodaje się_\n",
    "|9|_fenolami lotnymi_|_ręcznego miotacza_|_do spraw_|\n",
    "|10|_ostrzeżony strzałami_|_młyny kulowe_|_o którym_|\n",
    "\n",
    "### Trigram\n",
    "\n",
    "| #| PMI | PMI (>=5 wystąpień) | LLR |\n",
    "|-|-|-|-|\n",
    "|1|_ostrzeżony strzałami ostrzegawczymi_|_finałowego turnieju mistrzostw_|_o których mowa_|\n",
    "|2|_przekazowi pieniężnemu towarzyszyły_|_profilem zaufanym epuap_|_których mowa w_|\n",
    "|3|_grzyba synchytrium endobioticum_|_cienką sierścią zwierzęcą_|_o którym mowa_|\n",
    "|4|_clavibacter michiganensis ssp_|_przedwczesnego wyrębu drzewostanu_|_mowa w ust_|\n",
    "|5|_krzewiące etos społecznikowski_|_turnieju mistrzostw europy_|_mowa w art_|\n",
    "|6|_wniebowzięcia najświętszej maryi_|_potwierdzonym profilem zaufanym_|_którym mowa w_|\n",
    "|7|_najświętszej maryi panny_|_szybkiemu postępowi technicznemu_|_o której mowa_|\n",
    "|8|_salus aegroti suprema_|_piłce nożnej uefa_|_minister właściwy do_|\n",
    "|9|_aegroti suprema lex_|_centralnemu biuru antykorupcyjnemu_|_w drodze rozporządzenia_|\n",
    "|10|_prawosławnym metropolitą warszawskim_|_wypalonym paliwem jądrowym_|_właściwy do spraw_|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer the following questions:\n",
    "### Why do we have to filter the bigrams, rather than the token sequence?\n",
    "Gdybyśmy dokonali filtrowania na etapie tokenizacji, to później znaleźlibyśmy się w sytuacji, w której tokeny z niepowiązanych miejsc w tekście zostałyby zgrupowane jako n-gramy.\n",
    "### Which measure (PMI, PMI with filtering, LLR) works better for the bigrams and which for the trigrams? What types of expressions are discovered by the methods?\n",
    "Wydaje mi się, że w obydwu przypadkach ciekawsze zostały frazy znalezione przy pomocy PMI. W większości przypadków stanowią one spójne kolokacje (*nietykalność cielesną*, *klęskami żywiołowymi*, *centralnemu biuru antykorupcyjnemu*). Przy pomocy LLR znalezione zostały frazy mniej ciekawe pod względem samej semantyki (*o których mowa*, *w ust*, *o których*), choć oczywiście z nich również można wyciągnąć pewne wnioski. Odfiltrowanie rzadko występujących wyników PMI wydaje się dobrym pomysłem -- pomogło zlikwidować wyniki, w których słowa wydają się urwane (*torowiskach zasp*) czy ogólnie mniej zrozumiałe (*nająca pjm*), a także wszelkie sentencje łacińskie (*aegroti suprema lex*).\n",
    "### Can you devise a different type of filtering that would yield better results?\n",
    "Rozważyłabym filtrację *stop words* (choć w przypadku trigramów wydaje mi się, że warto byłoby zachować środkowe słowo ze względu na frazy typu *X orax Y*) lub ogólnie krótsze tokeny. Taka filtracja miałaby szczególnie duży wpływ na wyniki LLR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
